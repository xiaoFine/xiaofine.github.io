<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://xiaofine.github.io</id>
    <title>xiaoFine</title>
    <updated>2019-06-17T07:19:30.162Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://xiaofine.github.io"/>
    <link rel="self" href="https://xiaofine.github.io/atom.xml"/>
    <subtitle>有六层楼那么高</subtitle>
    <logo>https://xiaofine.github.io/images/avatar.png</logo>
    <icon>https://xiaofine.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, xiaoFine</rights>
    <entry>
        <title type="html"><![CDATA[Spark Submit中添加多个jar]]></title>
        <id>https://xiaofine.github.io/post/spark-submit-add-jar</id>
        <link href="https://xiaofine.github.io/post/spark-submit-add-jar">
        </link>
        <updated>2019-03-24T05:16:12.000Z</updated>
        <summary type="html"><![CDATA[<p>这次项目需要利用spark读取hbase，但在提交spark任务之后发现该集群没有为spark配置hbase相关的依赖，同时我们没有权限修改集群配置，因此只能通过spark submit时添加<code>--jar</code>参数来指定依赖。</p>
]]></summary>
        <content type="html"><![CDATA[<p>这次项目需要利用spark读取hbase，但在提交spark任务之后发现该集群没有为spark配置hbase相关的依赖，同时我们没有权限修改集群配置，因此只能通过spark submit时添加<code>--jar</code>参数来指定依赖。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[初始Yarn]]></title>
        <id>https://xiaofine.github.io/post/Yarn</id>
        <link href="https://xiaofine.github.io/post/Yarn">
        </link>
        <updated>2018-03-20T14:26:26.000Z</updated>
        <summary type="html"><![CDATA[<h4 id="yarn-mrv1">Yarn MRv1</h4>
<p>Hadoop的MapReduce原有架构主要由以下几个组件组成：Client、JobTracker、TaskTracker、Task。其架构图如下所示：
{%asset_img 20170808210130242.png%}
从上图中可以清楚的看出原 MapReduce 程序的流程及设计思路：</p>
<ol>
<li>首先用户程序 (JobClient) 提交了一个 job，job 的信息会发送到 <strong>Job Tracker</strong> 中，Job Tracker 是 Map-reduce 框架的中心，他需要与集群中的机器定时通信 (heartbeat), 需要管理哪些程序应该跑在哪些机器上，需要管理所有 job 失败、重启等操作。</li>
<li><strong>TaskTracker</strong> 是 Map-reduce 集群中每台机器都有的一个部分，他做的事情主要是监视自己所在机器的资源情况。</li>
<li>TaskTracker 同时监视当前机器的 tasks 运行状况。TaskTracker 需要把这些信息通过 heartbeat 发送给 JobTracker，JobTracker 会搜集这些信息以给新提交的 job 分配运行在哪些机器上。上图虚线箭头就是表示消息的发送 - 接收的过程。</li>
</ol>
]]></summary>
        <content type="html"><![CDATA[<h4 id="yarn-mrv1">Yarn MRv1</h4>
<p>Hadoop的MapReduce原有架构主要由以下几个组件组成：Client、JobTracker、TaskTracker、Task。其架构图如下所示：
{%asset_img 20170808210130242.png%}
从上图中可以清楚的看出原 MapReduce 程序的流程及设计思路：</p>
<ol>
<li>首先用户程序 (JobClient) 提交了一个 job，job 的信息会发送到 <strong>Job Tracker</strong> 中，Job Tracker 是 Map-reduce 框架的中心，他需要与集群中的机器定时通信 (heartbeat), 需要管理哪些程序应该跑在哪些机器上，需要管理所有 job 失败、重启等操作。</li>
<li><strong>TaskTracker</strong> 是 Map-reduce 集群中每台机器都有的一个部分，他做的事情主要是监视自己所在机器的资源情况。</li>
<li>TaskTracker 同时监视当前机器的 tasks 运行状况。TaskTracker 需要把这些信息通过 heartbeat 发送给 JobTracker，JobTracker 会搜集这些信息以给新提交的 job 分配运行在哪些机器上。上图虚线箭头就是表示消息的发送 - 接收的过程。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[初始Hadoop（三）：Hadoop读写]]></title>
        <id>https://xiaofine.github.io/post/hadoop3</id>
        <link href="https://xiaofine.github.io/post/hadoop3">
        </link>
        <updated>2018-03-18T07:27:42.000Z</updated>
        <summary type="html"><![CDATA[<p>在HDFS中，数据是以数据块（Block）的形式存储，不同版本Hadoop的默认块大小不同，128M或者64M。这个值可以用户自己定义。如果一个数据文件被划分成越小的数据块，HDFS读取这个文件时候的并发性也就更高。但是，也意味着将带来更多的磁盘寻道的IO开销，所以这是个trade-off。</p>
]]></summary>
        <content type="html"><![CDATA[<p>在HDFS中，数据是以数据块（Block）的形式存储，不同版本Hadoop的默认块大小不同，128M或者64M。这个值可以用户自己定义。如果一个数据文件被划分成越小的数据块，HDFS读取这个文件时候的并发性也就更高。但是，也意味着将带来更多的磁盘寻道的IO开销，所以这是个trade-off。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[初始Hadoop（二）：Hadoop架构]]></title>
        <id>https://xiaofine.github.io/post/hadoop2</id>
        <link href="https://xiaofine.github.io/post/hadoop2">
        </link>
        <updated>2018-03-17T05:45:42.000Z</updated>
        <summary type="html"><![CDATA[<p>HDFS是Hadoop Distributed File System的缩写，它采用了主从式的结构。根据节点角色的不同，可以主要分为 <strong>NameNode</strong> 和 <strong>DataNode</strong> （细分还包括Second Namenode，JournalNode等等）。</p>
]]></summary>
        <content type="html"><![CDATA[<p>HDFS是Hadoop Distributed File System的缩写，它采用了主从式的结构。根据节点角色的不同，可以主要分为 <strong>NameNode</strong> 和 <strong>DataNode</strong> （细分还包括Second Namenode，JournalNode等等）。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[初始Hadoop（一）：Hadoop概览]]></title>
        <id>https://xiaofine.github.io/post/hadoop1</id>
        <link href="https://xiaofine.github.io/post/hadoop1">
        </link>
        <updated>2018-03-16T08:07:53.000Z</updated>
        <summary type="html"><![CDATA[<p>Hadoop是一个于2011年，由Apache基金会所开发的分布式系统基础架构。它为我们提供了一个可靠的，可扩展的分布式计算框架。总的来说，Hadoop由四部分组成，包括:</p>
]]></summary>
        <content type="html"><![CDATA[<p>Hadoop是一个于2011年，由Apache基金会所开发的分布式系统基础架构。它为我们提供了一个可靠的，可扩展的分布式计算框架。总的来说，Hadoop由四部分组成，包括:</p>
]]></content>
    </entry>
</feed>